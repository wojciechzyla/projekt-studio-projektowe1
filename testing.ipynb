{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "cat_json = {}\n",
    "cat_txt = []\n",
    "with open(\"grouped_categories.json\") as f:\n",
    "    cat_json = json.load(f)\n",
    "\n",
    "with open(\"gm_places_categories.txt\") as f:\n",
    "    for l in f:\n",
    "        cat_txt.append(l.split(\"\\n\")[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accounting']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_from_json = set()\n",
    "distinct_txt = set(cat_txt)\n",
    "\n",
    "for k, v in cat_json.items():\n",
    "    for el in v:\n",
    "        distinct_from_json.add(el)\n",
    "\n",
    "not_used = list(distinct_txt.difference(distinct_from_json))\n",
    "not_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i really like visiting museums and exploring culture', 'i want to visit some cultural events', 'i prefer cheap accomodation']\n",
      "['i love going to the night clubs', 'i hope to go to parties in the evenings', 'during the day i want to fine dine and visit some bars']\n"
     ]
    }
   ],
   "source": [
    "texts = [\"\"\"I really like visiting museums and exploring culture. \n",
    "I want to visit some cultural events. I prefer cheap accomodation.\"\"\",\n",
    "        \"\"\"I love going to the night clubs. I hope to go to parties in the evenings. During the day I want to fine dine\n",
    "        and visit some bars.\"\"\"]\n",
    "\n",
    "from my_nlp_module.preprocessing import preprocess_document, PrepOption\n",
    "\n",
    "options = [PrepOption.NUMBERS, PrepOption.LOWERCASE, PrepOption.RUBBISH, PrepOption.INTERPUNCTION, PrepOption.TOKENIZE_SENTENCE]\n",
    "\n",
    "documents_preprocessed = []\n",
    "\n",
    "for doc in texts:\n",
    "    p = preprocess_document(doc, options)\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2838,  0.1310, -0.0029],\n",
      "        [ 0.2277, -0.0327, -0.0136],\n",
      "        [ 0.0543, -0.0502,  0.8939],\n",
      "        [-0.0114,  0.0125,  0.0397]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.28375503,  0.13100722, -0.00286157],\n",
       "       [ 0.22769953, -0.03272609, -0.01360959],\n",
       "       [ 0.05429638, -0.0501904 ,  0.89390373],\n",
       "       [-0.01136757,  0.0125467 ,  0.03974972]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Two lists of sentences\n",
    "sentences1 = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'The new movie is awesome',\n",
    "             \"Test sentence\"]\n",
    "\n",
    "sentences2 = ['The dog plays in the garden',\n",
    "              'A woman watches TV',\n",
    "              'The new movie is so great']\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarities\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "print(cosine_scores)\n",
    "cosine_scores = cosine_scores.numpy()\n",
    "cosine_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2838,  0.1310, -0.0029],\n",
      "        [ 0.2277, -0.0327, -0.0136],\n",
      "        [ 0.0543, -0.0502,  0.8939],\n",
      "        [-0.0114,  0.0125,  0.0397]])\n"
     ]
    }
   ],
   "source": [
    "print(cosine_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really like visiting museums and exploring culture. [0.48005053 0.         0.         0.        ] [0.48005053 0.         0.         0.        ]\n",
      "I want to visit some cultural events. [0.4649859  0.230849   0.22161081 0.        ] [0.4649859  0.230849   0.22161081 0.        ]\n",
      "I prefer expensive accomodation. [0.         0.         0.36597836 0.72362435] [0.         0.         0.36597836 0.72362435]\n",
      "I really like visiting museums and exploring culture. \n",
      "I want to visit some cultural events. I prefer expensive accomodation.\n",
      "[0.47251822 0.230849   0.29379459 0.72362435]\n",
      "\n",
      "\n",
      "I love going to the night clubs. [0.       0.518558 0.       0.      ] [0.       0.518558 0.       0.      ]\n",
      "I hope to go to parties in the evenings. [0.         0.45091712 0.         0.        ] [0.         0.45091712 0.         0.        ]\n",
      "During the day I want to fine dine and visit some bars. [0.         0.388821   0.3166833  0.26036456] [0.         0.388821   0.3166833  0.26036456]\n",
      "I love going to the night clubs. I hope to go to parties in the evenings. During the day I want to fine dine\n",
      "        and visit some bars.\n",
      "[0.         0.45276539 0.31668329 0.26036456]\n",
      "\n",
      "\n",
      "I hate going to the night clubs. [0.         0.5029496  0.         0.20642467] [0.         0.31132582 0.         0.12777688]\n",
      "I want to visit some cultural things. [0.46292514 0.         0.24948508 0.21916498] [0.46292514 0.         0.24948508 0.21916498]\n",
      "I hate going to the night clubs. I want to visit some cultural things.\n",
      "[0.46292514 0.31132582 0.24948508 0.17347093]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from my_nlp_module.preprocessing import preprocess_document, PrepOption\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "texts = [\"\"\"I really like visiting museums and exploring culture. \n",
    "I want to visit some cultural events. I prefer expensive accomodation.\"\"\",\n",
    "        \"\"\"I love going to the night clubs. I hope to go to parties in the evenings. During the day I want to fine dine\n",
    "        and visit some bars.\"\"\",\n",
    "        \"\"\"I hate going to the night clubs. I want to visit some cultural things.\"\"\"]\n",
    "\n",
    "templates = [\"museum history buildings culture tradition\", \"party nigh club clubs drinking alcohol\", \n",
    "             \"restaurant food expensive tasty\", \"cheap accomodation hostel\"]\n",
    "\n",
    "options1 = [PrepOption.TOKENIZE_SENTENCE]\n",
    "options2 = [PrepOption.NUMBERS, PrepOption.LOWERCASE, PrepOption.RUBBISH, PrepOption.INTERPUNCTION]\n",
    "\n",
    "\n",
    "for doc in texts:\n",
    "    sentences = preprocess_document(doc, options1)\n",
    "    n_topics = 4\n",
    "    doc_sim = np.zeros(shape=(n_topics))\n",
    "    normalization = [0 for i in range(n_topics)]\n",
    "    for s in sentences:\n",
    "        vs = analyzer.polarity_scores(s)\n",
    "        prep_sent = preprocess_document(s, options2)\n",
    "        embeddings1 = model.encode(prep_sent, convert_to_tensor=True)\n",
    "        embeddings2 = model.encode(templates, convert_to_tensor=True)\n",
    "        sim = util.cos_sim(embeddings1, embeddings2).numpy().squeeze()\n",
    "        for i in range(sim.shape[0]):\n",
    "            sim[i] = sim[i] if np.abs(sim[i])>0.2 else 0\n",
    "        norm_idx = np.where(sim!=0)[0]\n",
    "        for i in norm_idx:\n",
    "            normalization[i] += 1\n",
    "        print(s, sim, sim*(1-vs[\"neg\"]))\n",
    "        sim = sim*(1-vs[\"neg\"])\n",
    "        doc_sim += sim\n",
    "    for i, el in enumerate(normalization):\n",
    "        if el > 0:\n",
    "            doc_sim[i] /= el\n",
    "    #doc_sim /= len(sentences)\n",
    "    #doc_sim = (doc_sim + 1)/2\n",
    "    print(f\"{doc}\\n{doc_sim}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7479, 0.5993, 0.5858, 0.5853],\n",
       "        [0.5484, 0.7651, 0.5501, 0.5402],\n",
       "        [0.6818, 0.7333, 0.6194, 0.6339]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_preprocessed = []\n",
    "\n",
    "for doc in texts:\n",
    "    p = preprocess_document(doc, options1)\n",
    "    documents_preprocessed.append(p)\n",
    "\n",
    "embeddings1 = model.encode(documents_preprocessed, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(templates, convert_to_tensor=True)\n",
    "sim = util.cos_sim(embeddings1, embeddings2)\n",
    "(sim+1)/2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('env_travel': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a867fab74cd67586c6d03978805c3c3f7465035773807af503c86ba1d423217f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
