{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3926d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from my_nlp_module.preprocessing import preprocess_document, PrepOption\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "import nltk\n",
    "import re\n",
    "from my_nlp_module.tokenizer import Tokenizer\n",
    "\n",
    "path_to_model = \"../pretrained_models/40/model.bin\"\n",
    "model = KeyedVectors.load_word2vec_format(path_to_model, binary=True)\n",
    "embed_dim = model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58f39ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_doc_vector(document, embed_dim, embed_matrix):\n",
    "    result = np.zeros(embed_dim,)\n",
    "    for token in document:\n",
    "        if token != 0:\n",
    "            result += embed_matrix[token]\n",
    "    result /= len(document)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a0b59e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "preprocess_document() got an unexpected keyword argument 'language'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m documents_preprocessed \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[0;32m---> 16\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menglish\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     documents_preprocessed\u001b[38;5;241m.\u001b[39mappend(p)\n\u001b[1;32m     19\u001b[0m df_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m\"\u001b[39m: documents_preprocessed})\n",
      "\u001b[0;31mTypeError\u001b[0m: preprocess_document() got an unexpected keyword argument 'language'"
     ]
    }
   ],
   "source": [
    "texts = [\"\"\"I really like visiting museums and exploring culture. \n",
    "I want to visit some cultural events. I prefer cheap accomodation.\"\"\",\n",
    "        \"\"\"I love going to the night clubs. I hope to go to parties in the evenings. During the day I want to fine dine\n",
    "        and visit some bars.\"\"\"]\n",
    "\n",
    "templates = [\"museum history buildings culture tradition\", \"party nigh club clubs drinking alcohol\", \n",
    "             \"restaurant food expensive tasty\", \"cheap accomodation hostel\"]\n",
    "\n",
    "#options = [PrepOption.STOPWORDS, PrepOption.LOWERCASE, PrepOption.LEMMA, \n",
    "#           PrepOption.NUMBERS, PrepOption.RUBBISH, PrepOption.INTERPUNCTION]\n",
    "options = [PrepOption.NUMBERS, PrepOption.RUBBISH, PrepOption.INTERPUNCTION]\n",
    "\n",
    "documents_preprocessed = []\n",
    "\n",
    "for doc in texts:\n",
    "    p = preprocess_document(doc, options)\n",
    "    documents_preprocessed.append(p)\n",
    "        \n",
    "df_train = pd.DataFrame({\"document\": documents_preprocessed})\n",
    "df_templates = pd.DataFrame({\"document\": templates})\n",
    "\n",
    "df_combined = pd.DataFrame({\"document\": templates+documents_preprocessed})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2400fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 10000\n",
    "tok = Tokenizer(MAX_WORDS)\n",
    "tok.fit(list(df_combined['document']))\n",
    "vocab_size = len(tok.vocab) + 1\n",
    "\n",
    "embed_matrix=np.zeros(shape=(vocab_size,embed_dim))\n",
    "for word,i in tok.vocab.items():\n",
    "    try:\n",
    "        embed_vector=model[word]\n",
    "        embed_matrix[i]=embed_vector\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "print(f\"number of words {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bf5f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_texts = tok.texts_to_sequences(list(df_train['document']))\n",
    "encoded_templates = tok.texts_to_sequences(list(df_templates['document']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1635c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_vectors_texts = np.asarray([mean_doc_vector(encoded_texts[i], embed_dim, embed_matrix) \\\n",
    "                                for i in range(len(encoded_texts))])\n",
    "seq_vectors_templates = np.asarray([mean_doc_vector(encoded_templates[i], embed_dim, embed_matrix) \\\n",
    "                                for i in range(len(encoded_templates))])\n",
    "print(f\"Kształt wektorów treningowych: {seq_vectors_texts.shape}\\n\"\\\n",
    "     f\"Kształt wektorów testowych: {seq_vectors_templates.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df003c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "results = cosine_similarity(seq_vectors_texts, seq_vectors_templates)\n",
    "\n",
    "rows = []\n",
    "columns = [\"numer tekstu\", \"muzea itd.\", \"imprezy\", \"restauracje\", \"tani nocleg\"]\n",
    "for i in range(results.shape[0]):\n",
    "    row = [i]\n",
    "    for j in range(results.shape[1]):\n",
    "        row.append(results[i, j])\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "df\n",
    "# czym bardziej wartość bliższa 1 tym bardziej tekst jest podobny do danej kategorii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f20352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
